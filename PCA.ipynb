{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "x = loadmat('M1-DeepSquat.mat')\n",
    "correct = x['Train_Data']\n",
    "T1 = correct.shape[1]\n",
    "incorrect = x['Train_Data']\n",
    "T2 = incorrect.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Train_DataR=[]\n",
    "for i in range(T1):\n",
    "    Train_DataR.append(correct[0,i])\n",
    "for i in range(T2):\n",
    "    Train_DataR.append(incorrect[0,i])\n",
    "Train_DataR = np.dstack(Train_DataR)\n",
    "Train_DataR = np.rollaxis(Train_DataR,-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samples = Train_DataR.shape[0]\n",
    "timesteps = Train_DataR.shape[1]\n",
    "features = Train_DataR.shape[2]\n",
    "Train_DataR = np.reshape(Train_DataR,(samples,timesteps*features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(180, 28080)\n",
      "[[ 0.00451769 -0.44373948 -0.87325317 ...,  0.62097735 -1.09292898\n",
      "   0.06988442]\n",
      " [ 1.30641699  1.02287038 -1.44593675 ...,  0.56910386 -1.26720566\n",
      "   0.03529668]\n",
      " [ 1.72434021  0.79814422  0.33865749 ...,  2.29949444 -0.37643175\n",
      "   0.39953333]\n",
      " ..., \n",
      " [-1.25763747 -0.28477723 -0.68474651 ...,  0.09624289  1.08824293\n",
      "   1.23891632]\n",
      " [ 0.59169519 -1.44989865  0.92102143 ..., -0.53173523  1.06375237\n",
      "   2.95480093]\n",
      " [-0.45006554 -2.39069001  1.02218858 ..., -0.21890336  1.03319719\n",
      "   1.49223622]]\n"
     ]
    }
   ],
   "source": [
    "#Feature Scaling\n",
    "Train_DataR = StandardScaler().fit_transform(Train_DataR)\n",
    "print(Train_DataR.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n",
      "(180, 41)\n",
      "[[  3.57564904e+01  -3.62117028e+01  -2.05352691e+00 ...,  -6.99654496e+00\n",
      "    7.84168538e+00  -1.49126451e+01]\n",
      " [  1.67211702e+01  -2.64620703e+01   2.13679283e+01 ...,   7.57601016e+00\n",
      "   -1.32336712e+01  -1.04355426e+01]\n",
      " [  3.18320531e+01  -4.15507492e+01   1.32949606e+01 ...,  -5.64581708e+00\n",
      "   -2.82136533e+00   6.76267125e+00]\n",
      " ..., \n",
      " [ -6.97475878e+00   3.78404592e+01  -1.97822586e+01 ...,   4.99026117e-02\n",
      "    6.28668327e-01   9.39772571e+00]\n",
      " [  1.41704235e+01   4.02128461e+01  -4.99548589e+01 ...,  -6.44268109e+00\n",
      "   -1.17826579e+01   1.04903530e+01]\n",
      " [  2.68181840e+01   4.84617636e+01  -6.04162967e+01 ...,  -5.55888662e-01\n",
      "   -1.27653893e+01  -3.75591185e+00]]\n"
     ]
    }
   ],
   "source": [
    "#PCA\n",
    "pca = PCA(.95)\n",
    "pca.fit(Train_DataR)\n",
    "Train_DataR = pca.transform(Train_DataR)\n",
    "print(pca.n_components_)\n",
    "print(Train_DataR.shape)\n",
    "print(Train_DataR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Dynamic Time Warping\n",
    "from dtw import dtw\n",
    "euclidean_norm = lambda x, y: np.abs(x - y)\n",
    "dtw_list = np.zeros(samples)\n",
    "for i in range(samples):\n",
    "        for j in  range(samples):\n",
    "                dtw_list[i]= dtw_list[i] + dtw(Train_DataR[i,0:-1].tolist(),Train_DataR[j,0:-1].tolist(),dist=euclidean_norm)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'p = np.full((samples,1),\"Incorrect\")\\nfor i in range(T1):\\n    p[i] = \"Correct\"\\nTrain_DataR  = np.concatenate((Train_DataR,p),axis=1)\\nprint(Train_DataR.shape)\\nprint(Train_DataR)'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Adding Correct and Incorrect Labels\n",
    "p = np.full((samples,1),\"Incorrect\")\n",
    "for i in range(T1):\n",
    "    p[i] = \"Correct\"\n",
    "Train_DataR  = np.concatenate((Train_DataR,p),axis=1)\n",
    "print(Train_DataR.shape)\n",
    "print(Train_DataR)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
